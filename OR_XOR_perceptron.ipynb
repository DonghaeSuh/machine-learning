{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20211101 기계학습",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPiip9lGqzcVCyNdTkUSCLZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DonghaeSuh/machine-learning/blob/main/OR_XOR_perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2awlGU3glkBZ"
      },
      "source": [
        "### OR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z26Ur4WMbXVs"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#initalization of the perceptron\n",
        "W,b = np.array([0,0]),0.0\n",
        "learning_rate = 0.01\n",
        "\n",
        "def activation(s):\n",
        "  if(s>0): return 1\n",
        "  elif(s<0): return -1\n",
        "  return 0\n",
        "\n",
        "def out(x):\n",
        "  return activation(W.dot(x)+b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qky7-l3rgeUR"
      },
      "source": [
        "def train(x0,x1,target):\n",
        "  global W,b   #전역변수 사용\n",
        "  x= np.array([x0,x1])\n",
        "  y=out(x)\n",
        "\n",
        "  if target == y: return False    #맞는것은 바꿀필요 없음\n",
        "  print('before target : {} y:{} W:{} b: {}'.format(target,y,W,b))\n",
        "\n",
        "  #delta rule\n",
        "  W = W+learning_rate*x*target\n",
        "  b=b+learning_rate*target\n",
        "  print('after target:{} y:{} W:{} b:{}'.format(target,out(x),W,b))\n",
        "  return True\n",
        "\n",
        "def predict(inputs):\n",
        "  outputs = []\n",
        "  for x in inputs:\n",
        "    outputs.append(out(x))\n",
        "    return outputs\n",
        "       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAPSNqe_iLNT"
      },
      "source": [
        "#main\n",
        "adjusted = 0\n",
        "for i in range(100):\n",
        "  adjusted += train(-1,-1,-1)\n",
        "  adjusted += train(-1,+1,+1)\n",
        "  adjusted += train(+1,-1,+1)\n",
        "  adjusted += train(+1,+1,+1)\n",
        "\n",
        "  if adjusted == 0: break\n",
        "  adjusted =0\n",
        "\n",
        "  print('iteration ------------', i+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2qsbpfalhIO"
      },
      "source": [
        "### XOR  오류 찾아내자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWfr0tYmvlgp"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#initalization of the perceptron\n",
        "W= np.array([0,0,0,0])\n",
        "learning_rate = 0.01\n",
        "\n",
        "def activation(s):\n",
        "  if(s>0): return 1\n",
        "  elif(s<0): return -1\n",
        "  return 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVQePElfljJm"
      },
      "source": [
        "\n",
        "def out(polyX):\n",
        "  return activation(W.dot(polyX))\n",
        "\n",
        "def train(x0,x1,target):\n",
        "  global W  #전역변수 사용\n",
        "  polyX= np.array([x0,x1,x0*x1,1])\n",
        "  y=out(polyX)\n",
        "\n",
        "  if target == y: return False    #맞는것은 바꿀필요 없음\n",
        "  print('before target : {} y:{} W:{} '.format(target,y,W))\n",
        "\n",
        "  #delta rule\n",
        "  W = W+learning_rate*polyX*target\n",
        "  print('after target:{} y:{} W:{} '.format(target,out(polyX),W))\n",
        "  return True\n",
        "\n",
        "def predict(inputs):\n",
        "  outputs = []\n",
        "  for x in inputs:\n",
        "    polyX = np.array([x[0],x[1],x[0]*x[1],1])\n",
        "    outputs.append(out(polyX))\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii3-1jRLmYk4"
      },
      "source": [
        "#main\n",
        "adjusted = 0\n",
        "for i in range(100):\n",
        "  adjusted += train(-1,-1,-1)\n",
        "  adjusted += train(-1,+1,+1)\n",
        "  adjusted += train(+1,-1,+1)\n",
        "  adjusted += train(+1,+1,+1)\n",
        "\n",
        "  if adjusted == 0: break\n",
        "  adjusted =0\n",
        "\n",
        "  print('iteration ------------', i+1)\n",
        "\n",
        "X = [[-1,-1],[-1,1],[1,-1],[1,1]]\n",
        "yhat = predict(X)\n",
        "print('x0,x1,y')\n",
        "for i in range(len(X)):\n",
        "  print('{:2d} {:2d} {:2d}'.format(X[i][0],X[i][1],yhat[i]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}